{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c24758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0424725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21ca259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data and tokenize text\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "inputs = tokenizer.encode_plus(data[\"text\"].tolist(), \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512, \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "433a6d3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m----> 8\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# Train GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for batch in inputs:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e31c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for text in data[\"text\"]:\n",
    "    encoded_input = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, return_attention_mask=True, return_tensors=\"pt\")\n",
    "    inputs.append(encoded_input)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "batch_size = 32\n",
    "data_loader = torch.utils.data.DataLoader(inputs, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded2333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d7ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "inputs = []\n",
    "for text in data[\"text\"]:\n",
    "    encoded_input = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, return_attention_mask=True, return_tensors=\"pt\")\n",
    "    inputs.append(encoded_input[\"input_ids\"].flatten())\n",
    "\n",
    "# Pad the inputs to the same length\n",
    "padded_inputs = pad_sequence(inputs, batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df53db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(input_text):\n",
    "    inputs = tokenizer.encode_plus(input_text, add_special_tokens=True, max_length=512, return_attention_mask=True, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=30, early_stopping=True, eos_token_id=tokenizer.encode(\"[END]\")[0])\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ded690ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:58 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I cancel my order?\n",
      "\n",
      "I don't know what's wrong with that. I'm not sure. I'm not sure. I'm\n"
     ]
    }
   ],
   "source": [
    "input_text =  \"Can I cancel my order?\"\n",
    "response = generate_response(input_text)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3de6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personalized Customer Engagement\n",
    "def generate_engagement_message(customer_data, interaction_history):\n",
    "    input_text = customer_data + interaction_history\n",
    "    inputs = tokenizer.encode_plus(input_text, \n",
    "                                     add_special_tokens=True, \n",
    "                                     max_length=512, \n",
    "                                     return_attention_mask=True, \n",
    "                                     return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs[\"input_ids\"], \n",
    "                              attention_mask=inputs[\"attention_mask\"], \n",
    "                              max_length=128)\n",
    "    message = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0e2d483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sophia Patel, age 29, interests: yoga, wellnessPrevious purchases: gaming console, tech accessories, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer, computer,\n"
     ]
    }
   ],
   "source": [
    "customer_data = \"Sophia Patel, age 29, interests: yoga, wellness\"\n",
    "interaction_history = \"Previous purchases: gaming console, tech accessories\"\n",
    "message = generate_engagement_message(customer_data, interaction_history)\n",
    "print(message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf4297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
